{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow.contrib.slim.python.slim.nets.inception_v3 as inception_v3\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parser(record):\n",
    "    img_features = tf.parse_single_example(\n",
    "            record,\n",
    "            features={ 'Label'    : tf.FixedLenFeature([], tf.int64),\n",
    "                       'image_raw': tf.FixedLenFeature([], tf.string),\n",
    "                       'height':tf.FixedLenFeature([],tf.int64),\n",
    "                       'width':tf.FixedLenFeature([],tf.int64),\n",
    "                       'channel':tf.FixedLenFeature([],tf.int64)})\n",
    "    height = tf.cast(img_features['height'], tf.int64)\n",
    "    width = tf.cast(img_features['width'], tf.int64)\n",
    "    channel = tf.cast(img_features['channel'], tf.int64)\n",
    "#     image_shape = tf.parallel_stack([height, width, channel])\n",
    "    label = tf.cast(img_features['Label'], tf.int64)\n",
    "    \n",
    "    image = tf.decode_raw(img_features['image_raw'], tf.uint8)\n",
    "    image = tf.reshape(image, [299,299,3])\n",
    "#     image.set_shape([299,299,3])\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_for_train(image):\n",
    "    image_data = tf.image.resize_images(image,[299,299],method=0)\n",
    "    image_data = tf.image.random_saturation(image_data,lower=0.3,upper=1.3)\n",
    "    image_data = tf.image.random_brightness(image_data,max_delta=60. /255.) #亮度\n",
    "#     image_data = tf.image.random_contrast(image_data,0.5,1.5)\n",
    "    image_data = tf.image.random_flip_left_right(image_data)\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = tf.train.match_filenames_once(\"./data/Train.tfrecords\")\n",
    "dataset = tf.data.TFRecordDataset(train_files)\n",
    "dataset = dataset.map(parser)\n",
    "\n",
    "test_files = tf.train.match_filenames_once(\"./data/Train.tfrecords\")\n",
    "test_dataset = tf.data.TFRecordDataset(test_files)\n",
    "test_dataset = test_dataset.map(parser)\n",
    "\n",
    "dataset = dataset.map(\n",
    "    lambda image,label:(\n",
    "        preprocess_for_train(image),label))\n",
    "dataset = dataset.shuffle(2000).batch(8)\n",
    "\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda image,label:(\n",
    "        tf.image.resize_images(image,[299,299],method=0),label))\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tuned_variable():\n",
    "    exclusions = [scope.strip() for scope in CHECKPOINT_EXCLUDE_SCOPES.split(\",\")]\n",
    "    variable_to_restore = []\n",
    "#     slim.get_variables_to_restore()\n",
    "    for var in slim.get_model_variables():\n",
    "        excluded = False\n",
    "        for exclusion in exclusions:\n",
    "            if var.op.name.startswith(exclusion):\n",
    "                excluded = True\n",
    "                break\n",
    "        if not excluded:\n",
    "            variable_to_restore.append(var)\n",
    "    return variable_to_restore\n",
    "\n",
    "def get_trainable_variable():\n",
    "    scopes = [scope.strip() for scope in TRAINBLE_SCOPES.split(\",\")]\n",
    "    variable_to_train = []\n",
    "    for scope in scopes:\n",
    "        variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,scope)\n",
    "        variable_to_train.append(variables)\n",
    "    return variable_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 20\n",
    "dataset = dataset.repeat(NUM_EPOCH)\n",
    "Label_size = 830\n",
    "\n",
    "iterator = dataset.make_initializable_iterator()\n",
    "image_batch,label_batch = iterator.get_next()\n",
    "\n",
    "test_iterator = test_dataset.make_initializable_iterator()\n",
    "test_image_batch,test_label_batch = test_iterator.get_next()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "CKPT_FILE = \"inception_v3.ckpt\"\n",
    "MODEL_SAVE = \"./transfer_model\"\n",
    "\n",
    "CHECKPOINT_EXCLUDE_SCOPES = \"InceptionV3/Logits,InceptionV3/AuxLogits\"\n",
    "\n",
    "TRAINBLE_SCOPES = \"InceptionV3/Logits,InceptionV3/AuxLogits\"\n",
    "\n",
    "learning_rate = 0.0001\n",
    "batch_size = 8\n",
    "#tf.reset_default_graph() \n",
    "\n",
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "def weight_variable(shape):\n",
    "    return tf.Variable(initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(initializer(shape))\n",
    "\n",
    "def conv2d(x,W):\n",
    "    return tf.nn.conv2d(x,W,strides=[1,1,1,1],padding=\"SAME\")\n",
    "\n",
    "def max_pool(x):\n",
    "    return tf.nn.max_pool(x,ksize=[1,4,4,1],strides=[1,4,4,1],padding=\"SAME\")\n",
    "\n",
    "x = tf.placeholder(tf.float32,[None,299,299,3])\n",
    "y = tf.placeholder(tf.int32,[None])\n",
    "image_labels = tf.one_hot(y,Label_size)\n",
    "\n",
    "with slim.arg_scope(inception_v3.inception_v3_arg_scope()):\n",
    "    logits,_ = inception_v3.inception_v3(x,num_classes=Label_size)\n",
    "\n",
    "trainable_variable = get_trainable_variable()\n",
    "\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=image_labels,logits=logits))\n",
    "    tf.summary.scalar('loss',loss)\n",
    "with tf.name_scope('train'):\n",
    "#     train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "with tf.name_scope('evaluation'):\n",
    "    with tf.name_scope('correct_prediction'):  \n",
    "        correct_prediction = tf.equal(tf.argmax(logits,1),tf.argmax(image_labels,1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "        tf.summary.scalar('accuracy',accuracy)\n",
    "        \n",
    "load_fn = slim.assign_from_checkpoint_fn(\n",
    "    CKPT_FILE,\n",
    "    get_tuned_variable(),\n",
    "    ignore_missing_vars=True\n",
    ")\n",
    "\n",
    "merged = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from inception_v3.ckpt\n",
      "0.008384147 6.9812703\n",
      "0.0060975607 6.6870527\n",
      "0.006859756 6.5500846\n",
      "0.011779379 6.428483\n",
      "0.013719512 6.3462524\n",
      "0.017114745 6.247007\n",
      "0.017530488 6.157304\n",
      "0.022865854 6.085096\n",
      "0.026261086 5.9564896\n",
      "0.023628049 5.8510528\n",
      "0.025914634 5.769358\n",
      "0.019817073 5.6991334\n",
      "0.037347563 5.6067066\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'err' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5fb9d8c22869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimage_batch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mcount\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5fb9d8c22869>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;31m#                 print('Iter %d, accuracy %4.2f%%' % (count, train_accuracy*100))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[1;32mexcept\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Done\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'err' is not defined"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    load_fn(sess)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(iterator.initializer)\n",
    "    \n",
    "    count = 0\n",
    "    while True:\n",
    "        try:\n",
    "            image,label = sess.run([image_batch,label_batch])\n",
    "            sess.run(train_step, feed_dict={x: image, y: label})\n",
    "            count+=1\n",
    "            if count % 100 == 0:\n",
    "                sess.run(test_iterator.initializer)\n",
    "                test_acc = []\n",
    "                test_losses = []\n",
    "                while True:\n",
    "                    try:\n",
    "                        test_image,test_label = sess.run([test_image_batch,test_label_batch])\n",
    "                        test_accuracy,test_loss = sess.run([accuracy,loss],feed_dict={x: test_image,y:test_label})\n",
    "                        test_acc.append(test_accuracy)\n",
    "                        test_losses.append(test_loss)\n",
    "                    except:\n",
    "                        print(np.mean(test_acc),np.mean(test_losses))\n",
    "                        break\n",
    "#                     image,label = sess.run([image_batch,label_batch])\n",
    "#                 train_accuracy = accuracy.eval(feed_dict={x: image, y: label})\n",
    "#                 print('Iter %d, accuracy %4.2f%%' % (count, train_accuracy*100))\n",
    "            \n",
    "        except err:\n",
    "            print(err)\n",
    "            print(\"Done\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* LOSS 下降速度太慢(Learning rate 過小)，缺Training_acc,Training_loss，沒畫圖。 之後更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
